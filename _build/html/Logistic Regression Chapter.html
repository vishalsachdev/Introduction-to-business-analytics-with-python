
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Logistic Regression &#8212; Introduction to Business Analytics with Python</title>
    
  <link href="_static/css/theme.css" rel="stylesheet" />
  <link href="_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/sphinx-book-theme.acff12b8f9c144ce68a297486a2fa670.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Multiple Linear Regression" href="MLR.html" />
    <link rel="prev" title="LASSO Regression" href="LASSO.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
      
      <h1 class="site-logo" id="site-title">Introduction to Business Analytics with Python</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="DM%20Overview%20Chapter%202%20Draft%20v2.html">
   Data Mining Overview (Cont.)
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="EDA%20%26%20Data%20Viz.%20Chapter%203%20Draft%20v2.html">
   EDA and Data Visualization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="LASSO.html">
   LASSO Regression
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Logistic Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="MLR.html">
   Multiple Linear Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Similarity%20%26%20Clustering%20Chapter%204%20Draft%20v2.html">
   Similarity &amp; Clustering
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/Logistic Regression Chapter.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/vishalsachdev/Introduction-to-business-analytics-with-python/main?urlpath=tree/Logistic Regression Chapter.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-is-logistic-regression">
   What is Logistic Regression?
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-is-logistic-regression-helpful">
     How is Logistic Regression Helpful?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-logistic-function">
   The Logistic Function
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#odds-ratio">
     Odds Ratio
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#classifiers">
   Classifiers
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#confusion-matrix">
   Confusion Matrix
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#roc-curve">
   ROC Curve
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="logistic-regression">
<h1>Logistic Regression<a class="headerlink" href="#logistic-regression" title="Permalink to this headline">¶</a></h1>
<div class="section" id="what-is-logistic-regression">
<h2>What is Logistic Regression?<a class="headerlink" href="#what-is-logistic-regression" title="Permalink to this headline">¶</a></h2>
<p><span style="color:orange"><strong>Logistic regression</strong> </span>is a form of supervised learning that uses past data to predict the value of the outcome. Although it has “regression” in the name, logistic regression is actually used for classification.</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:center head"><p><img alt="Classification vs Regression" src="attachment:classification_vs_regression.png" /></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:center"><p><b>Fig. # - Classification predicts discrete variables, like True/False, Yes/No. Regression predicts continuous variables, like Age, Salary, and Income.</b></p></td>
</tr>
</tbody>
</table>
<p>As discussed in Chapter X, the main difference between classification and regression deals with the dependent variable. When it comes to classification, you’re working with categorical variables. This means, you’re either predicting whether or not an observation belongs to a certain class, or the probability of your observation belonging to a specific class. For regression, on the other hand, you’re predicting a continuous, numerical amount.</p>
<p>Since logistic regression models are used for classification, their goal is to determine the binary dependent variable. So, situations depicting logistic regression will only have <strong>two potential outcomes</strong> that are clearly distinguished.</p>
<p>Some examples of logistic regression include:</p>
<ul class="simple">
<li><p>Identifying whether a tumor is malignant <em>or</em> benign</p></li>
<li><p>Detecting whether an email is spam <em>or</em> legitimate</p></li>
<li><p>Predicting whether a student will pass <em>or</em> fail a class</p></li>
</ul>
<p>Now, let’s look at an example together. Imagine you’re working at a bank, and your job is to determine whether or not a customer will accept a loan. Whether or not the customer accepts the loan will be the outcome variable. Our predictors will be factors such as demographics, income, and the customer’s relationship with the bank. Let’s take this step by step.</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:center head"><p><img alt="Logistic_reg_cutoff" src="attachment:logistic_reg_cutoff.png" /></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:center"><p><b>Fig. # - In this logit graph, the orange line represents the cutoff point. This line will determine which class an individual belongs to. </b></p></td>
</tr>
</tbody>
</table>
<p>In the graph above, the orange line represents our cutoff point. So, if our input variable, income, falls below that orange cutoff line, it will equate to a value of ‘0’. This means that the customer will not accept the loan offer. On the flip side, if income is above that orange cutoff line, it will equate to a value of ‘1’. In that case, we would assume the customer would accept the loan offer.</p>
<div class="section" id="how-is-logistic-regression-helpful">
<h3>How is Logistic Regression Helpful?<a class="headerlink" href="#how-is-logistic-regression-helpful" title="Permalink to this headline">¶</a></h3>
<p>As you can see from the example above, there are a lot of benefits to using logistic regression models:</p>
<ul class="simple">
<li><p>They’re helpful when dealing with several predictor variables</p></li>
<li><p>They provide a clear and definitive answer (Yes/No, Pass/Fail, True/False, etc.)</p></li>
<li><p>They can readily updated with new data</p></li>
</ul>
<p>The main drawback with logistic regression, however, is its limited curve. Since it can only produce values between 0 and 1, these models are unable to showcase complex relationships.</p>
</div>
</div>
<div class="section" id="the-logistic-function">
<h2>The Logistic Function<a class="headerlink" href="#the-logistic-function" title="Permalink to this headline">¶</a></h2>
<div class="math notranslate nohighlight">
\[
log(odds) = \beta_{0} + \beta_{1}x_{1} + \beta_{2}x_{2} + ... + \beta_{p}x_{p} 
\]</div>
<p>If you’re looking at this equation and thinking to yourself, <em>Hey, this kind of looks familiar</em>, then you’d be thinking correctly. If you recall from our past chapter about Multiple Linear Regression, the right half of this equation is the same as the equation for MLR. The only differences are that (1) instead of it being equal to Y, in this case, the function is equal to log(odds), and (2) the equation does not account for error, or E. log(odds) is also called a <span style="color:orange"><strong>logit function</strong>. </span></p>
<div class="section" id="odds-ratio">
<h3>Odds Ratio<a class="headerlink" href="#odds-ratio" title="Permalink to this headline">¶</a></h3>
<p>Consider this scenario: you’re watching a game, where a highly skilled (Team A) is playing an amateur one (Team B), and Team A wins 4 out of 5 matches. So, Team A has won 4 games and lost 5. In this case, the odds of Team A winning are 4:1, while the probability of them winning is ⅘. Alternatively, Team B’s odds of winning are 1:4, while the probability of them winning is ⅕.</p>
<p>As you can see, <strong>odds and probabilities are not the same</strong>. An <span style="color:orange"><strong>odds ratio</strong> </span> can be defined as the likelihood of something occurring divided by the likelihood that it won’t. <span style="color:orange"><strong>Probability</strong> </span>, on the other hand, is defined as the number of favorable outcomes (in this case, Team A winning, if you’re rooting for Team A) divided by the total number of outcomes. Both are ways of expressing the likelihood of something happening; they’re just calculated differently.</p>
<p>What’s nice about these two functions is that you can find one by calculating the other. Once you know the frequencies of Win/Loss, True/False, Yes/No, etc., you can calculate either odds or probabilities.</p>
<div class="math notranslate nohighlight">
\[
Odds(Y=1) = p/(1-p)
\]</div>
<div class="math notranslate nohighlight">
\[
p = odds/(1+odds)
\]</div>
<p>Furthermore, if the odds are against Team A winning, then they will be between 0 and 1 (ex. 1/32); if the odds Team A winning are good, then the odds will be between 1 and infinity (ex. 32/3).</p>
<p>Comparing these odds can be a bit difficult, but if we were to use a log function, it would be much clearer. The following example is inspired from the YouTube video, “StatQuest: Odds and Log(Odds), Clearly Explained!!!”, as linked <a class="reference external" href="https://www.youtube.com/watch?v=ARfXDSkQf1Y">here</a>.</p>
<p>Let’s say the odds are 1 to 5. If the odds are against 1 to 5, then that means the odds are 0.2. On the flip side, that means the odds are in favor of 5 to 1, then the odds are 5. Obviously, the magnitude of the left side (in orange) is drastically different from the odds on the right side (blue). This makes the problem asymmetrical and hard to understand.</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:center head"><p><img alt="Asymmetrical Odds" src="attachment:prob_vs_odds_asymmetric.png" /></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:center"><p><b>Fig. # - When problems are asymmetrical, they can become difficult to understand.</b></p></td>
</tr>
</tbody>
</table>
<p>So, as we learned in the StatQuest video, this is where logs can come in handy. If the odds against were 1 to 5, the log(odds) are -1.39, and if the odds are in favor 5 to 1, the log(odds) are 1.39. After using the log function to analyze the odds, we see the magnitude of the distance from the center remains the same.</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:center head"><p><img alt="Symmetrical Odds" src="attachment:prob_vs_odds_symmetric.png" /></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:center"><p><b>Fig. # - By using a log function, it makes it easier to analyze the odds of a situation.</b></p></td>
</tr>
</tbody>
</table>
<p>Let’s go back to the logit function we just learned about for a second.</p>
<p>In our last chapter about MLR, the lowercase “x” variables on the right side of the equation are called “predictors”. When it comes to linear functions, their outcome variables are continuous and can therefore have an infinite number of possible values.</p>
<p>However, logistic functions are binary. So, the addition of the log in the equation ensures that predictor values (which measure probability) fall between 0 and 1. Since we know the probability of the function, we can then find the odds. For logit functions, the overall graph ranges from -∞ and +∞, since log(0) = -∞ and log(1) = +∞.</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:center head"><p><img alt="S-LinePredictor" src="attachment:s_line_predictor_val.png" /></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:center"><p><b>Fig. # - Logit graphs closely resemble an S-shape, and can be reflected across the y-axis due to their perfect symmetry.</b></p></td>
</tr>
</tbody>
</table>
<p>As you can see above, a logit graph has perfect symmetry and is centered at 0. It closely resembles an S-shape.</p>
<p>Overall, the odds are just the ratio of something happening to something not happening. The log of those odds makes things symmetrical and easier to interpret.</p>
</div>
</div>
<div class="section" id="classifiers">
<h2>Classifiers<a class="headerlink" href="#classifiers" title="Permalink to this headline">¶</a></h2>
<p>So, now we know that logistic regression is a form of classification. But how exactly does classification work?</p>
<p><img alt="Classification Summary.png" src="attachment:classification_summary_2.png" /></p>
<p>As you can see from the table above, we determine the “class” of inputs based on the probability of it to be true (also known as <em>propensity</em>). One way we can do this is by creating cutoff values; if the probability is greater or equal to the cutoff, then we predict “yes”. If the probability is less than the cutoff, then we predict “no”.</p>
<p><strong>How do we determine the cutoff value of X?</strong></p>
<p>When answering this question, there are three main things to keep in mind:</p>
<ol class="simple">
<li><p>The incorrect way of predicting class is by setting all classifiers towards the most common prediction. This would set all values to either “yes” or “no” depending on what is most popular.</p></li>
<li><p>The most popular cutoff value is X = 0.5, which serves as the initial choice until a more accurate value is determined.</p></li>
<li><p>In order to maximize classification accuracy, you should center X according to the set of data at hand.</p></li>
</ol>
<p>Although we can determine the cutoff value, there are better ways of evaluating the accuracy of the classifier. To be specific, we can use a confusion matrix and/or an ROC curve and then adjust the value of this cutoff.</p>
</div>
<div class="section" id="confusion-matrix">
<h2>Confusion Matrix<a class="headerlink" href="#confusion-matrix" title="Permalink to this headline">¶</a></h2>
<p>A <span style="color:orange"><strong>confusion matrix</strong> </span> is a table that is used to describe the performance of classification models, or “classifiers.” It is also known as a “classification matrix”.</p>
<p>We often see or hear of these measures in the real world, but they are not always easily identifiable as “confusion matrices”. Take, for example, testing the accuracy of new coronavirus detecting tests.</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:center head"><p><img alt="Confusion Matrix - General" src="attachment:confusion_matrix_general.png" /></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:center"><p><b>Fig. # - When measuring the performance of a classification model, these four quartiles help determine the effectiveness of the test. </b></p></td>
</tr>
</tbody>
</table>
<p>To visualize how a confusion matrix is created, we can create a table with values of the actual outcome and predicted outcome, as determined by regression. After setting our cutoff value at 5, we can then categorize our values to either “Yes” or “No”.</p>
<p><img alt="Actual Predicted Outcome Table" src="attachment:actual_pred_outcome_table.png" /></p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:center head"><p><img alt="Confusion Matrix Values.png" src="attachment:confusion_matrix_values.png" /></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:center"><p><b>Fig. # - In order to measure classification accuracy, you must look at the matrix from a mathematical perspective.</b></p></td>
</tr>
</tbody>
</table>
<p>Although the classification matrix itself is pretty easy to understand, sometimes the terminology can be a bit confusing. Below is a reference of all the formulas you’ll need to know:</p>
<ul class="simple">
<li><p><strong>N</strong> = # of observation = TP + TN + FP + FN</p></li>
<li><p><strong>Sensitivity =</strong> TP/(TP+FN)</p></li>
<li><p><strong>Specificity =</strong> TN/(TN+FP)</p></li>
<li><p><strong>False Negative Rate =</strong> FN/(TP+FN)</p></li>
<li><p><strong>False Positive Rate =</strong> FP/(TN+FP)</p></li>
<li><p><strong>Overall accuracy</strong> = (TP+TN)/N</p></li>
<li><p><strong>Overall error rate</strong> = (FP+FN)/N</p>
<ul>
<li><p>The sum of overall accuracy AND overall error rate will <strong>always equal 1</strong>.</p></li>
</ul>
</li>
</ul>
<p><span style="color:orange"><strong>Sensitivity</strong> </span> is also known as the True Positive Rate, which defines your success of accurately labeling an instance as true. It is also known as “recall.” <span style="color:orange"><strong>Specificity</strong> </span> is also known as the True Negative Rate, which defines your success of accurately labeling an instance as false.</p>
<p>There is a tradeoff between sensitivity and specificity when running these tests. You have to decide which measure is more important based on the case being discussed.</p>
</div>
<div class="section" id="roc-curve">
<h2>ROC Curve<a class="headerlink" href="#roc-curve" title="Permalink to this headline">¶</a></h2>
<p>Lastly, below we have an ROC Curve, or a Receiver Operating Characteristic Curve. The <strong>ROC curve</strong> graphs sensitivity (the true positive rate) on the y-axis and 1-specificity (the false positive rate) on the x-axis. The curve shows the performance of a classification model at all classification thresholds. Its main goal is to identify as many true positives as possible, while minimizing the amount of false positives.</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:center head"><p><img alt="ROC Curve" src="attachment:roc_curve.png" /></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:center"><p><b>Fig. # -  The closer the ROC curve is to being a perfect classifier, the more accurate it is.</b></p></td>
</tr>
</tbody>
</table>
<p>By using an ROC curve, we can determine the best cutoff for the best trade-off. The trade-off is measured between False Negative and False Positive Rate.</p>
<p>If the cutoff value (t) is large, then the False Positive Rate should be low and the False Negative Rate should be high. In contrast, if the t-value is small, then the False Positive Rate should be high and the False Negative Rate should be low.</p>
<p>Let’s take a closer look at the graph above. As you can see, the arrow points upward, indicating that the closer you get to that straight purple line, the better (or more accurate) you will be. You can also measure how accurate the test is by referencing the AUC, or Area Under the Curve. If the AUC is 0.5, then it’s a random classifier, as shown with the red dotted line. If the AUC is 1, then it’s a perfect classifier, as shown in the purple.</p>
<p>One last statistic we will look at is the average misclassification cost. This is the calculated cost of incorrectly classifying an observation. In other words, what is the cost of classifying an event as being “No”, when in reality it was “Yes” and vice-versa. In this formula, Q1 is referencing FP (False Positive), while Q2 is referencing FN (False Negative).</p>
<p><span style="color:orange"><strong>Average Misclassification Cost</strong> </span>
$<span class="math notranslate nohighlight">\(
(Q1*FP + Q2*FN)/N
\)</span>$</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="LASSO.html" title="previous page">LASSO Regression</a>
    <a class='right-next' id="next-link" href="MLR.html" title="next page">Multiple Linear Regression</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Vishal Sachdev<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>